{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于mnist数据集，建立mlp模型，实现0-9数字的十分类task:\n",
    "    \n",
    "    - 实现mnist数据载入，可视化图形数字\n",
    "    - 完成数据预处理，图像数据维度转换与归一化、输出结果格式转换\n",
    "    - 计算模型在预测数据集的准确率\n",
    "    - 模型结构：两层隐藏层，每层有392个神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the mnist data\n",
    "from keras.datasets import mnist\n",
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train),X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize the data\n",
    "img1 = X_train[0]\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "fig1 = plt.figure(figsize=(5,5))\n",
    "plt.imshow(img1)\n",
    "plt.title(y_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "#format the input data\n",
    "feature_size = img1.shape[0]*img1.shape[1]\n",
    "X_train_format = X_train.reshape(X_train.shape[0],feature_size)\n",
    "X_test_format = X_test.reshape(X_test.shape[0],feature_size)\n",
    "\n",
    "print(X_train_format.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#normlize the input data\n",
    "X_train_normal = X_train_format/255\n",
    "X_test_normal = X_test_format/255\n",
    "print(X_train_normal[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#format the output data(labels)\n",
    "from keras.utils import to_categorical\n",
    "y_train_format = to_categorical(y_train)\n",
    "y_test_format = to_categorical(y_test)\n",
    "print(y_train_format[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 392)               154056    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                3930      \n",
      "=================================================================\n",
      "Total params: 465,706\n",
      "Trainable params: 465,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#set up the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(units=392,activation='sigmoid',input_dim=feature_size))\n",
    "mlp.add(Dense(units=392,activation='sigmoid'))\n",
    "mlp.add(Dense(units=10,activation='softmax'))\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the model\n",
    "mlp.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3437\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1462\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0933\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0665\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0494\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0361\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0277\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0206\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0176\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24186c898c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "mlp.fit(X_train_normal,y_train_format,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-e75cb4ef2afd>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "y_train_predict = mlp.predict_classes(X_train_normal)\n",
    "print(y_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9965333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_train = accuracy_score(y_train,y_train_predict)\n",
    "print(accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9801\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = mlp.predict_classes(X_test_normal)\n",
    "accuracy_test = accuracy_score(y_test,y_test_predict)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img2 = X_test[100]\n",
    "fig2 = plt.figure(figsize=(3,3))\n",
    "plt.imshow(img2)\n",
    "plt.title(y_test_predict[100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像数字多分类实战summary:\n",
    "\n",
    "- 通过mlp模型，实现了基于图像数据的数字自动识别分类：\n",
    "- 完成了图像的数字化处理可视化\n",
    "- 对mlp模型的输入、输出数据格式有了更深的认识，完成了数据预处理与格式转换\n",
    "- 建立了结构更为复杂的mlp模型\n",
    "- mnist数据集地址：http://yann.lecun.com/exdb/mnist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
